{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import endomill\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_packs = (\n",
    "    [\n",
    "        {\n",
    "            \"MILL_TREATMENT_NAME\": \"bottleneck\",\n",
    "            \"MILL_NPOP_SEQ\": \"[100] * 67 + [10] * 66 + [100] * 67\",\n",
    "            \"MILL_REPLICATE\": replicate,\n",
    "        }\n",
    "        for replicate in range(10)\n",
    "    ]\n",
    "    + [\n",
    "        {\n",
    "            \"MILL_TREATMENT_NAME\": \"control\",\n",
    "            \"MILL_REPLICATE\": replicate,\n",
    "        }\n",
    "        for replicate in range(10)\n",
    "    ]\n",
    "    + [\n",
    "        {\n",
    "            \"MILL_TREATMENT_NAME\": \"selection-pressure\",\n",
    "            \"MILL_NTOURN_SEQ\": \"[8] * 67 + [1] * 66 + [8] * 67\",\n",
    "            \"MILL_REPLICATE\": replicate,\n",
    "        }\n",
    "        for replicate in range(10)\n",
    "    ]\n",
    "    + [\n",
    "        {\n",
    "            \"MILL_TREATMENT_NAME\": \"range-expansion\",\n",
    "            \"MILL_REPLICATE\": replicate,\n",
    "            \"MILL_NPOP_SEQ\": \"[10] * 67 + [*range(10, 142, 2)] + [142] * 67\",\n",
    "        }\n",
    "        for replicate in range(10)\n",
    "    ]\n",
    ")\n",
    "\n",
    "for i, pp in enumerate(parameter_packs):\n",
    "    with open(f\"Ne-inference-parameterization-{i}.yaml\", \"w\") as file:\n",
    "        yaml.safe_dump(pp, file)\n",
    "# endomill.instantiate_over(parameter_packs=parameter_packs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Papermill Parameters\n"
   ]
  },
  {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
      "tags": ["parameters"]
    },
    "outputs": [],
    "source": [
      "MILL_NPOP_SEQ: str = \"[100] * 200\"\n",
      "MILL_NTOURN_SEQ: str = \"[2] * 200\"\n",
      "MILL_TREATMENT_NAME: str  # = \"control\"\n",
      "MILL_REPLICATE: int  # = 0\n"
    ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MILL_NPOP_SEQ = eval(MILL_NPOP_SEQ)\n",
    "MILL_NTOURN_SEQ = eval(MILL_NTOURN_SEQ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import itertools as it\n",
    "import typing\n",
    "import random\n",
    "\n",
    "import alifedata_phyloinformatics_convert as apc\n",
    "from deap import algorithms as deap_algorithms\n",
    "from deap import base as deap_base\n",
    "from deap import creator as deap_creator\n",
    "from deap import tools as deap_tools\n",
    "\n",
    "from hstrat import hstrat\n",
    "from iterpop import iterpop as ip\n",
    "from keyname import keyname as kn\n",
    "from matplotlib import pyplot as plt\n",
    "from nbmetalog import nbmetalog as nbm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats as scipy_stats\n",
    "import seaborn as sns\n",
    "import sympy\n",
    "from teeplot import teeplot as tp\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pylib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(MILL_REPLICATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbm.print_metadata()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HSTRAT_RESOLUTION = None\n",
    "HSTRAT_DIFFERENTIA_WIDTH = 64\n",
    "NGEN = ip.pophomogeneous([len(MILL_NPOP_SEQ), len(MILL_NTOURN_SEQ)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deap_creator.create(\"FitnessMax\", deap_base.Fitness, weights=(1.0,))\n",
    "deap_creator.create(\"Individual\", list, fitness=deap_creator.FitnessMax)\n",
    "\n",
    "toolbox = deap_base.Toolbox()\n",
    "\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "toolbox.register(\n",
    "    \"individual\",\n",
    "    deap_tools.initRepeat,\n",
    "    deap_creator.Individual,\n",
    "    toolbox.attr_bool,\n",
    "    n=100,\n",
    ")\n",
    "toolbox.register(\"population\", deap_tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "\n",
    "def evalOneMax(individual):\n",
    "    return (sum(individual),)\n",
    "\n",
    "\n",
    "toolbox.register(\"evaluate\", evalOneMax)\n",
    "toolbox.register(\"mate\", deap_tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", deap_tools.mutFlipBit, indpb=0.05)\n",
    "\n",
    "# Decorate the variation operators\n",
    "history = deap_tools.History()\n",
    "toolbox.decorate(\"mate\", history.decorator)\n",
    "\n",
    "toolbox.decorate(\"mate\", pylib.deap.hstrat_mate_decorator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the population and populate the history\n",
    "population = toolbox.population(n=MILL_NPOP_SEQ[0])\n",
    "\n",
    "species_ancestor = hstrat.HereditaryStratigraphicColumn(\n",
    "    stratum_retention_policy=hstrat.perfect_resolution_algo.Policy(),\n",
    "    stratum_differentia_bit_width=HSTRAT_DIFFERENTIA_WIDTH,\n",
    ")\n",
    "gene_ancestor = hstrat.HereditaryStratigraphicColumn(\n",
    "    stratum_retention_policy=hstrat.perfect_resolution_algo.Policy(),\n",
    "    stratum_differentia_bit_width=HSTRAT_DIFFERENTIA_WIDTH,\n",
    "    initial_stratum_annotation=0,\n",
    ")\n",
    "for member in population:\n",
    "    member.species_annotation = species_ancestor.CloneDescendant()\n",
    "    member.gene_annotation = gene_ancestor.CloneDescendant(0)\n",
    "\n",
    "history.update(population)\n",
    "\n",
    "# Do the evolution, the decorators will take care of updating the\n",
    "# history\n",
    "for _gen, (NPOP, NTOURN) in tqdm(\n",
    "    enumerate(\n",
    "        zip(\n",
    "            MILL_NPOP_SEQ,\n",
    "            MILL_NTOURN_SEQ,\n",
    "        )\n",
    "    )\n",
    "):\n",
    "    toolbox.register(\"select\", deap_tools.selTournament, tournsize=NTOURN)\n",
    "    offspring = deap_algorithms.varAnd(\n",
    "        population, toolbox, cxpb=1.0, mutpb=1.0,\n",
    "    )\n",
    "    fits = toolbox.map(toolbox.evaluate, offspring)\n",
    "    for fit, ind in zip(fits, offspring):\n",
    "        ind.fitness.values = fit\n",
    "    population = toolbox.select(offspring, k=NPOP)\n",
    "    population = [copy.deepcopy(ind) for ind in population]\n",
    "\n",
    "# ensure all extant organisms registered with phylogeny tracker\n",
    "for x in population:\n",
    "    history.update([x])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extant_nodes = [individual.history_index for individual in population]\n",
    "reconstructed_df = hstrat.build_tree(\n",
    "    [individual.species_annotation for individual in population],\n",
    "    version_pin=hstrat.__version__,\n",
    "    force_common_ancestry=True,\n",
    "    taxon_labels=map(str, extant_nodes),\n",
    ")\n",
    "reconstructed_df[\"name\"] = reconstructed_df[\"taxon_label\"]\n",
    "reconstructed_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_tree = apc.alife_dataframe_to_biopython_tree(\n",
    "    reconstructed_df, setup_branch_lengths=True\n",
    ")\n",
    "tp.tee(\n",
    "    pylib.tree.draw_biopython_tree,\n",
    "    reconstructed_tree,\n",
    "    teeplot_outattrs={\n",
    "        \"notebook\": \"ne-inference\",\n",
    "        \"replicate\": str(MILL_REPLICATE),\n",
    "        \"treatment\": MILL_TREATMENT_NAME,\n",
    "        \"type\": \"reconstruction\",\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_tree = apc.alife_dataframe_to_biopython_tree(\n",
    "    reconstructed_df, setup_branch_lengths=True\n",
    ")\n",
    "tp.tee(\n",
    "    pylib.tree.draw_biopython_tree,\n",
    "    reconstructed_tree,\n",
    "    drop_overlapping_labels=True,\n",
    "    teeplot_outattrs={\n",
    "        \"drop_overlapping_labels\": \"true\",\n",
    "        \"notebook\": \"ne-inference\",\n",
    "        \"replicate\": str(MILL_REPLICATE),\n",
    "        \"treatment\": MILL_TREATMENT_NAME,\n",
    "        \"type\": \"reconstruction\",\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_tree = apc.alife_dataframe_to_biopython_tree(\n",
    "    reconstructed_df, setup_branch_lengths=True\n",
    ")\n",
    "tp.tee(\n",
    "    pylib.tree.draw_biopython_tree,\n",
    "    reconstructed_tree,\n",
    "    max_leaves=20,\n",
    "    teeplot_outattrs={\n",
    "        \"max_leaves\": \"20\",\n",
    "        \"notebook\": \"ne-inference\",\n",
    "        \"replicate\": str(MILL_REPLICATE),\n",
    "        \"treatment\": MILL_TREATMENT_NAME,\n",
    "        \"type\": \"reconstruction\",\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Pedigree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilled_tree = pylib.deap.history_to_tree_upgma(history, extant_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.tee(\n",
    "    pylib.tree.draw_biopython_tree,\n",
    "    distilled_tree,\n",
    "    teeplot_outattrs={\n",
    "        \"notebook\": \"ne-inference\",\n",
    "        \"replicate\": str(MILL_REPLICATE),\n",
    "        \"treatment\": MILL_TREATMENT_NAME,\n",
    "        \"type\": \"distilled-reference\",\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.tee(\n",
    "    pylib.tree.draw_biopython_tree,\n",
    "    distilled_tree,\n",
    "    drop_overlapping_labels=True,\n",
    "    teeplot_outattrs={\n",
    "        \"drop_overlapping_labels\": \"true\",\n",
    "        \"notebook\": \"ne-inference\",\n",
    "        \"replicate\": str(MILL_REPLICATE),\n",
    "        \"treatment\": MILL_TREATMENT_NAME,\n",
    "        \"type\": \"distilled-reference\",\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.tee(\n",
    "    pylib.tree.draw_biopython_tree,\n",
    "    distilled_tree,\n",
    "    max_leaves=20,\n",
    "    teeplot_outattrs={\n",
    "        \"max_leaves\": \"20\",\n",
    "        \"notebook\": \"ne-inference\",\n",
    "        \"replicate\": str(MILL_REPLICATE),\n",
    "        \"treatment\": MILL_TREATMENT_NAME,\n",
    "        \"type\": \"distilled-reference\",\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilled_tree = pylib.deap.history_to_tree_upgma(\n",
    "    history, extant_nodes, correct_origin_times=False\n",
    ")\n",
    "pylib.tree.polymorphic_quartet_distance(reconstructed_tree, distilled_tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentia Magnitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_data = dict(population[0].species_annotation.IterRankDifferentiaZip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatterplot_differentia_magnitude():\n",
    "#     plt.plot(*[*zip(*enumerate(MILL_NPOP_SEQ))])\n",
    "\n",
    "    sns.scatterplot(\n",
    "        x=rd_data.keys(),\n",
    "        y=rd_data.values(),\n",
    "        c=\"k\",\n",
    "    )\n",
    "\n",
    "    for i, (a, b) in enumerate(it.pairwise(MILL_NPOP_SEQ)):\n",
    "        if abs(a - b) > 2:\n",
    "            plt.axvline(i + 1, c=\"white\", lw=6)\n",
    "\n",
    "            plt.axvline(i + 1, ls=\":\", c=\"red\")\n",
    "    for i, (a, b) in enumerate(it.pairwise(MILL_NTOURN_SEQ)):\n",
    "        if a != b:\n",
    "            plt.axvline(i + 1, c=\"white\", lw=6)\n",
    "            plt.axvline(i + 1, ls=\":\", c=\"red\")\n",
    "\n",
    "    plt.ylabel(\"fixed differentia magnitude\")\n",
    "    plt.xlabel(\"generation\")\n",
    "\n",
    "tp.tee(\n",
    "    scatterplot_differentia_magnitude,\n",
    "    teeplot_outattrs={\n",
    "        \"notebook\": \"ne-inference\",\n",
    "        \"replicate\": str(MILL_REPLICATE),\n",
    "        \"treatment\": MILL_TREATMENT_NAME,\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatterplot_popsize_estimates():\n",
    "    plt.plot(*[*zip(*enumerate(MILL_NPOP_SEQ))])\n",
    "\n",
    "    sns.scatterplot(\n",
    "        x=rd_data.keys(),\n",
    "       y=[\n",
    "            -1 / np.log(x / 2**HSTRAT_DIFFERENTIA_WIDTH)\n",
    "            for x in rd_data.values()\n",
    "        ],\n",
    "        c=\"k\",\n",
    "    )\n",
    "\n",
    "    for i, (a, b) in enumerate(it.pairwise(MILL_NPOP_SEQ)):\n",
    "        if abs(a - b) > 2:\n",
    "            plt.axvline(i + 1, c=\"white\", lw=6)\n",
    "\n",
    "            plt.axvline(i + 1, ls=\":\", c=\"red\")\n",
    "    for i, (a, b) in enumerate(it.pairwise(MILL_NTOURN_SEQ)):\n",
    "        if a != b:\n",
    "            plt.axvline(i + 1, c=\"white\", lw=6)\n",
    "            plt.axvline(i + 1, ls=\":\", c=\"red\")\n",
    "\n",
    "    plt.ylabel(\"estimated population size\")\n",
    "    plt.xlabel(\"generation\")\n",
    "\n",
    "tp.tee(\n",
    "    scatterplot_popsize_estimates,\n",
    "    teeplot_outattrs={\n",
    "        \"notebook\": \"ne-inference\",\n",
    "        \"replicate\": str(MILL_REPLICATE),\n",
    "        \"treatment\": MILL_TREATMENT_NAME,\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO pool strata to create a running estimate with 95% confidence interval bands\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"rank\": rd_data.keys(),\n",
    "        \"differentia\": rd_data.values(),\n",
    "    }\n",
    ")\n",
    "\n",
    "df[\"normalized differentia\"] = (\n",
    "    df[\"differentia\"] / 2**HSTRAT_DIFFERENTIA_WIDTH\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/mmore500/hereditary-stratigraph-concept/blob/3ebe7a7f3f03c03592564a64b0024632888d8f1d/binder/popsize/maximum_likelihood_popsize_estimator_confidence_interval.ipynb\n",
    "def solve_mle_popsize_ci_lb(\n",
    "    observations: typing.List[float],\n",
    "    *,\n",
    "    confidence: float = 0.95,\n",
    ") -> float:\n",
    "\n",
    "    k = len(observations)\n",
    "    hat_x = math.prod(observations)\n",
    "\n",
    "    # use mle estimate as starting guess\n",
    "    hat_n_mle = -k / math.log(hat_x)\n",
    "\n",
    "    n_lb = sympy.Symbol(\n",
    "        \"n_\\mathrm{lb}\",\n",
    "        positive=True,\n",
    "        real=True,\n",
    "    )\n",
    "\n",
    "    return float(\n",
    "        sympy.nsolve(\n",
    "            2 * sympy.uppergamma(k, -n_lb * sympy.log(hat_x))\n",
    "            - (confidence + 1) * sympy.gamma(k),\n",
    "            hat_n_mle,\n",
    "            verify=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def solve_mle_popsize_ci_ub(\n",
    "    observations: typing.List[float],\n",
    "    *,\n",
    "    confidence: float = 0.95,\n",
    ") -> float:\n",
    "\n",
    "    k = len(observations)\n",
    "    hat_x = math.prod(observations)\n",
    "\n",
    "    # use mle estimate as starting guess\n",
    "    hat_n_mle = -k / math.log(hat_x)\n",
    "\n",
    "    n_lb = sympy.Symbol(\n",
    "        \"n_\\mathrm{ub}\",\n",
    "        positive=True,\n",
    "        real=True,\n",
    "    )\n",
    "\n",
    "    return float(\n",
    "        sympy.nsolve(\n",
    "            2 * sympy.uppergamma(k, -n_lb * sympy.log(hat_x))\n",
    "            - (1 - confidence) * sympy.gamma(k),\n",
    "            hat_n_mle,\n",
    "            verify=False,\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the pooled running estimate\n",
    "k = 10\n",
    "\n",
    "df[\"running_ub\"] = (\n",
    "    df[\"normalized differentia\"]\n",
    "    .rolling(window=k)\n",
    "    .apply(solve_mle_popsize_ci_ub)\n",
    ")\n",
    "df[\"running_lb\"] = (\n",
    "    df[\"normalized differentia\"]\n",
    "    .rolling(window=k)\n",
    "    .apply(solve_mle_popsize_ci_lb)\n",
    ")\n",
    "df[\"population size\"] = (\n",
    "    df[\"normalized differentia\"]\n",
    "    .rolling(window=k)\n",
    "    .apply(lambda x: -k / np.sum(np.log(x)))\n",
    ")\n",
    "\n",
    "k = 1\n",
    "df[\"population size from singleton\"] = (\n",
    "    df[\"normalized differentia\"]\n",
    "    .rolling(window=k)\n",
    "    .apply(lambda x: -k / np.sum(np.log(x)))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_running_estimation(x, y, data):\n",
    "    plt.plot(*[*zip(*enumerate(MILL_NPOP_SEQ))])\n",
    "\n",
    "    sns.lineplot(\n",
    "        data=data,\n",
    "        x=x,\n",
    "        y=y,\n",
    "        c=\"k\",\n",
    "    )\n",
    "\n",
    "    for i, (a, b) in enumerate(it.pairwise(MILL_NPOP_SEQ)):\n",
    "        if abs(a - b) > 2:\n",
    "            plt.axvline(i + 1, c=\"white\", lw=6)\n",
    "            plt.axvline(i + 1, ls=\":\", c=\"red\")\n",
    "\n",
    "    for i, (a, b) in enumerate(it.pairwise(MILL_NTOURN_SEQ)):\n",
    "        if a != b:\n",
    "            plt.axvline(i + 1, c=\"white\", lw=6)\n",
    "            plt.axvline(i + 1, ls=\":\", c=\"red\")\n",
    "\n",
    "    plt.fill_between(\n",
    "        df[\"rank\"], df[\"running_ub\"], df[\"running_lb\"], fc=\"lightblue\"\n",
    "    )\n",
    "\n",
    "\n",
    "tp.tee(\n",
    "    plot_running_estimation,\n",
    "    x=\"rank\",\n",
    "    y=\"population size\",\n",
    "    data=df,\n",
    "    teeplot_outattrs={\n",
    "        \"notebook\": \"ne-inference\",\n",
    "        \"replicate\": str(MILL_REPLICATE),\n",
    "        \"treatment\": MILL_TREATMENT_NAME,\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = [\n",
    "    {\n",
    "        \"notebook\": \"ne-inference\",\n",
    "        \"replicate\": MILL_REPLICATE,\n",
    "        \"treatment\": MILL_TREATMENT_NAME,\n",
    "        \"first rank\": first_rank,\n",
    "        \"population size estimate at first rank\": df[\n",
    "            df[\"rank\"] == first_rank\n",
    "        ].iloc[0][\"population size\"],\n",
    "        \"population size upper bound at first rank\": df[\n",
    "            df[\"rank\"] == first_rank\n",
    "        ].iloc[0][\"running_ub\"],\n",
    "        \"population size lower bound at first rank\": df[\n",
    "            df[\"rank\"] == first_rank\n",
    "        ].iloc[0][\"running_lb\"],\n",
    "        \"second rank\": second_rank,\n",
    "        \"population size estimate at second rank\": df[\n",
    "            df[\"rank\"] == second_rank\n",
    "        ].iloc[0][\"population size\"],\n",
    "        \"population size upper bound at second rank\": df[\n",
    "            df[\"rank\"] == second_rank\n",
    "        ].iloc[0][\"running_ub\"],\n",
    "        \"population size lower bound at second rank\": df[\n",
    "            df[\"rank\"] == second_rank\n",
    "        ].iloc[0][\"running_lb\"],\n",
    "        \"nonoverlapping CI\": min(\n",
    "            df[df[\"rank\"] == first_rank].iloc[0][\"running_ub\"],\n",
    "            df[df[\"rank\"] == second_rank].iloc[0][\"running_ub\"],\n",
    "        )\n",
    "        < max(\n",
    "            df[df[\"rank\"] == first_rank].iloc[0][\"running_lb\"],\n",
    "            df[df[\"rank\"] == second_rank].iloc[0][\"running_lb\"],\n",
    "        ),\n",
    "        \"Mann-Whitney p\": scipy_stats.mannwhitneyu(\n",
    "            df.loc[\n",
    "                (df[\"rank\"] - first_rank).abs() < 15,\n",
    "                \"population size from singleton\",\n",
    "            ],\n",
    "            df.loc[\n",
    "                (df[\"rank\"] - second_rank).abs() < 15,\n",
    "                \"population size from singleton\",\n",
    "            ],\n",
    "        )[1],\n",
    "    }\n",
    "    for first_rank, second_rank in it.permutations([33, 100, 166], 2)\n",
    "]\n",
    "outdf = pd.DataFrame.from_records(records)\n",
    "outdf[\"Mann-Whitney significant at alpha = 0.05\"] = (\n",
    "    outdf[\"Mann-Whitney p\"] < 0.05\n",
    ")\n",
    "outdf[\"Mann-Whitney significant at alpha = 0.01\"] = (\n",
    "    outdf[\"Mann-Whitney p\"] < 0.01\n",
    ")\n",
    "outdf.to_csv(\n",
    "    kn.pack(\n",
    "        {\n",
    "            \"a\": \"snapshot-comparisons-stats\",\n",
    "            \"notebook\": \"ne-inference\",\n",
    "            \"replicate\": MILL_REPLICATE,\n",
    "            \"treatment\": MILL_TREATMENT_NAME,\n",
    "            \"ext\": \".csv\",\n",
    "        }\n",
    "    )\n",
    ")\n",
    "outdf\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
